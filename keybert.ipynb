{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bf43c5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keybert\n",
      "  Downloading keybert-0.8.2.tar.gz (29 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting sentence-transformers>=0.3.8 (from keybert)\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "     ---------------------------------------- 0.0/86.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 86.0/86.0 kB 4.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from keybert) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from keybert) (1.23.5)\n",
      "Collecting rich>=10.4.0 (from keybert)\n",
      "  Obtaining dependency information for rich>=10.4.0 from https://files.pythonhosted.org/packages/be/2a/4e62ff633612f746f88618852a626bbe24226eba5e7ac90e91dcfd6a414e/rich-13.6.0-py3-none-any.whl.metadata\n",
      "  Downloading rich-13.6.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich>=10.4.0->keybert) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich>=10.4.0->keybert) (2.15.1)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich>=10.4.0->keybert) (4.7.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (2.2.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (4.29.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (2.0.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (0.15.2a0)\n",
      "Requirement already satisfied: nltk in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (3.8.1)\n",
      "Collecting sentencepiece (from sentence-transformers>=0.3.8->keybert)\n",
      "  Downloading sentencepiece-0.1.99-cp38-cp38-win_amd64.whl (977 kB)\n",
      "     ---------------------------------------- 0.0/977.6 kB ? eta -:--:--\n",
      "     -------------------- ---------------- 532.5/977.6 kB 11.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- --- 890.9/977.6 kB 9.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 977.6/977.6 kB 7.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (0.15.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.9.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2023.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (23.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers>=0.3.8->keybert) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (0.13.2)\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers>=0.3.8->keybert) (8.0.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision->sentence-transformers>=0.3.8->keybert) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (1.3.0)\n",
      "Downloading rich-13.6.0-py3-none-any.whl (239 kB)\n",
      "   ---------------------------------------- 0.0/239.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 239.8/239.8 kB 14.3 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: keybert, sentence-transformers\n",
      "  Building wheel for keybert (setup.py): started\n",
      "  Building wheel for keybert (setup.py): finished with status 'done'\n",
      "  Created wheel for keybert: filename=keybert-0.8.2-py3-none-any.whl size=39190 sha256=589f003f1c3a3bbc38062d2aea697fd00f32e6cf4d1e5fa64bf42d090fd5fe4c\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\37\\86\\b5\\1d3dce3685364cfd2e9934204c3a41094f81c52e01522de032\n",
      "  Building wheel for sentence-transformers (setup.py): started\n",
      "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125960 sha256=0e1099c6a62a31ecef84b9c8b2ae2569bdd4e0c4da459004db2c861c4c35b64d\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\5e\\6f\\8c\\d88aec621f3f542d26fac0342bef5e693335d125f4e54aeffe\n",
      "Successfully built keybert sentence-transformers\n",
      "Installing collected packages: sentencepiece, rich, sentence-transformers, keybert\n",
      "Successfully installed keybert-0.8.2 rich-13.6.0 sentence-transformers-2.2.2 sentencepiece-0.1.99\n"
     ]
    }
   ],
   "source": [
    "!pip install keybert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3a5ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keybert import KeyBERT\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4722bad",
   "metadata": {},
   "source": [
    "## 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12248fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일 경로\n",
    "csv_file_path = './data/RSS_total.csv'\n",
    "\n",
    "# CSV 파일을 pandas DataFrame으로 읽기\n",
    "df = pd.read_csv(csv_file_path,encoding='ANSI')\n",
    "\n",
    "# KeyBERT 모델 로드\n",
    "model = KeyBERT('distilbert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124d5285",
   "metadata": {},
   "source": [
    "## 모델 적용 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "572a569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 추출 함수 정의\n",
    "def extract_keywords(text, num_keywords=5):\n",
    "    keywords = model.extract_keywords(text, keyphrase_ngram_range=(1, 1), stop_words='english', use_maxsum=True, nr_candidates=20)\n",
    "    return [keyword[0] for keyword in keywords[:num_keywords]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b850f02e",
   "metadata": {},
   "source": [
    "## 범위 바꿔가며 데이터 한 번 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b83f97f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101    The following are today's upgrades for Validea...\n",
       "102    (RTTNews) - The following are some of the stoc...\n",
       "103    (RTTNews) - The following are some of the stoc...\n",
       "104    --LifeMD, Inc., a leading direct-to-patient te...\n",
       "105    Know Labs, Inc., an emerging developer of non-...\n",
       "Name: news_smy_ifo, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['news_smy_ifo'][101:106]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa41979",
   "metadata": {},
   "source": [
    "## 추출 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5955039b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101       [valley, small, upgrades, investor, bancorp]\n",
       "102             [50, big, trading, rttnews, wednesday]\n",
       "103             [50, big, trading, rttnews, wednesday]\n",
       "104    [b2b, today, companies, telehealth, healthcare]\n",
       "105      [developer, new, glucose, hospital, diabetes]\n",
       "Name: news_smy_ifo, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 행에 대한 키워드 추출 및 결과 저장\n",
    "result = df['news_smy_ifo'][101:106].apply(extract_keywords)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c9d569",
   "metadata": {},
   "source": [
    "## 데이터 정제하기\n",
    "\n",
    "숫자 데이터와 신문사 데이터는 노이즈로 작용할 확률이 높다고 판단해 제거하기로 결정함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1662cbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In trading on Wednesday, shares of Dada Nexus Ltd (Symbol: DADA) crossed below their 200 day moving average of $7.59, changing hands as low as $7.52 per share. Dada Nexus Ltd shares are currently trading off about 4.5% on the day. The chart below shows the one year performanc\n",
      "------------\n",
      "In trading on Wednesday, shares of Dada Nexus Ltd  crossed below their  day moving average of $., changing hands as low as $. per share. Dada Nexus Ltd shares are currently trading off about .% on the day. The chart below shows the one year performanc\n"
     ]
    }
   ],
   "source": [
    "# 제거 실습\n",
    "original_string = df.news_smy_ifo[10000]\n",
    "print(original_string)\n",
    "modified_string = re.sub(r'\\([^)]*\\)|\\d+', '', original_string)\n",
    "print('------------')\n",
    "print(modified_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463816d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 제거하며 데이터프레임 수정\n",
    "for i in range(len(df)):\n",
    "    df.news_smy_ifo[i] = re.sub(r'\\([^)]*\\)|\\d+', '', df.news_smy_ifo[i])\n",
    "    if i % 1000 == 0:\n",
    "        print('+1000 complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a56cdbd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" - The following are some of the stocks making big moves in Wednesday's pre-market trading .\""
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과확인\n",
    "df.news_smy_ifo[102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "27395b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 파일로 저장 (최초 한 번만)\n",
    "#df.to_csv('./data/RSS_for_keybert.csv', index=False, encoding='ANSI')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d8bfb3",
   "metadata": {},
   "source": [
    "## 키워드 추출 (뒤에서 부터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "114bb1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)//1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29832cfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keys = pd.DataFrame()\n",
    "keys['result'] = ['nan'] * len(df)\n",
    "for i in range(0,len(df)//1000):\n",
    "    keys['result'][len(df)-1-1000*i:len(df)-1-1000*(i+1):-1] = df['news_smy_ifo'][len(df)-1-1000*i:len(df)-1-1000*(i+1):-1].apply(extract_keywords)\n",
    "    print(1000*i, 'complete')\n",
    "    \n",
    "keys['result'][len(df)-1-1000*146::-1] = df['news_smy_ifo'][len(df)-1-1000*146::-1].apply(extract_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "bdd342bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)-1000*146):\n",
    "    keys['result'][i] = extract_keywords(df['news_smy_ifo'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe28e6d4",
   "metadata": {},
   "source": [
    "## 결과 확인 & 오류 검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "82131ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stonex', 'vrtv', 'stocks', 'week', 'january']\n",
      "['performanc', 'trading', 'dada', 'low', 'wednesday']\n",
      "['research', 'zacks', 'global', 'mastercard', 'august']\n"
     ]
    }
   ],
   "source": [
    "# 결과 확인\n",
    "print(keys['result'][999])\n",
    "print(keys['result'][10000])\n",
    "print(keys['result'][110000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d842ff37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[natural, group, disclosing, lp, gas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[light, analysts, weeks, stock, beaten]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[flying, yellow, disconnect, investors, oil]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[french, agribusiness, oldest, monday, beer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[flying, yellow, disconnect, investors, oil]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         result\n",
       "0         [natural, group, disclosing, lp, gas]\n",
       "1       [light, analysts, weeks, stock, beaten]\n",
       "2  [flying, yellow, disconnect, investors, oil]\n",
       "3  [french, agribusiness, oldest, monday, beer]\n",
       "4  [flying, yellow, disconnect, investors, oil]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a8774a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keys) == len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f8972862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "result    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "966d4960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# 추출과정에 참여하지 못한 누락된 인덱스가 있는지\n",
    "count = 0\n",
    "for i in range(len(keys)):\n",
    "    if keys['result'][i] == 'nan':\n",
    "        print(i)\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "8b06dd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "total : 0\n"
     ]
    }
   ],
   "source": [
    "# 잘못 매칭된 데이터가 있는지\n",
    "count = 0\n",
    "for i in range(len(keys)):\n",
    "    for k in keys['result'][i]:\n",
    "        if k not in df['news_smy_ifo'][i].lower():\n",
    "            print(i)\n",
    "            count += 1\n",
    "print('-----------------------')\n",
    "print('total :',count)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06281688",
   "metadata": {},
   "source": [
    "## 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f5dd41ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일로\n",
    "keys.to_csv('./data/keybert_result.csv', index=False,encoding='ANSI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "6e638863",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_df = pd.read_csv('./data/keybert_result.csv',encoding='ANSI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "1ff72c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "result    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3a4ca9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle 파일로\n",
    "import pickle\n",
    "with open('./data/keybert_result.pickle', 'wb') as file:\n",
    "    pickle.dump(keys, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "54ae5da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "result    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data/keybert_result.pickle', 'rb') as file:\n",
    "    keys_df = pickle.load(file)\n",
    "    \n",
    "key_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "03ba2f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['natural', 'group', 'disclosing', 'lp', 'gas']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['light', 'analysts', 'weeks', 'stock', 'beaten']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['flying', 'yellow', 'disconnect', 'investors'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['french', 'agribusiness', 'oldest', 'monday',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['flying', 'yellow', 'disconnect', 'investors'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              result\n",
       "0    ['natural', 'group', 'disclosing', 'lp', 'gas']\n",
       "1  ['light', 'analysts', 'weeks', 'stock', 'beaten']\n",
       "2  ['flying', 'yellow', 'disconnect', 'investors'...\n",
       "3  ['french', 'agribusiness', 'oldest', 'monday',...\n",
       "4  ['flying', 'yellow', 'disconnect', 'investors'..."
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
